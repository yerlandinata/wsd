{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Lexical-Sample WSD Dataset Builder from Wikipedia Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import string\n",
    "from preprocessor import clean_word, stemmer, pipe\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_real_sentence = lambda s: len(s) > 10 and s[0] in string.ascii_letters  and '|' not in s and '=' not in s and 'html' not in s and ':' not in s\n",
    "\n",
    "# depending on the circumstances, stemmer.stem should or should not be added to the pipe\n",
    "def is_containing_exactly_one_chosen_word(sentence, chosen):\n",
    "    return list(map(pipe(clean_word), sentence.split())).count(chosen) == 1\n",
    "\n",
    "def get_discourse_id(s):\n",
    "    tokens = s.strip().split('<id>')\n",
    "    return tokens[-1].replace('</id>', '').replace('\\n.', '') if len(tokens) == 2 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open('../idwiki-latest-pages-articles-full.xml', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def execute():\n",
    "    current_discourse = None\n",
    "    kalimat = []\n",
    "    discourse = []\n",
    "    kata = []\n",
    "    valid_discourse_id = False\n",
    "    WIKI_LEN = len(raw)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for line in raw:\n",
    "        sentences = []\n",
    "        for s in line.split('.'):\n",
    "            sentences.append(s + '.')\n",
    "        for s in sentences:\n",
    "            if '<title>' in s:\n",
    "                valid_discourse_id = True\n",
    "                continue\n",
    "            next_discourse = get_discourse_id(s)\n",
    "            if next_discourse and valid_discourse_id:\n",
    "                current_discourse = next_discourse\n",
    "                valid_discourse_id = False\n",
    "                continue\n",
    "            if not is_real_sentence(s):\n",
    "                continue\n",
    "            if is_containing_exactly_one_chosen_word(s, chosen_word):\n",
    "                s = s.replace('[[', '').replace(']]', '').replace('\\n', '').replace(\"''\", \"\").replace(\"'''\", \"\").replace('&quot;', '')\n",
    "                kalimat.append(s)\n",
    "                kata.append(chosen_word)\n",
    "                discourse.append(current_discourse)\n",
    "        if len(kalimat) >= TARGET_SIZE:\n",
    "            print('\\ntarget achieved')\n",
    "            break\n",
    "        i += 1\n",
    "        if i % (WIKI_LEN//500) == 0:\n",
    "            sys.stdout.write(\"\\rRaw read: {0:.1f} % | Instance collected: {1}\".format(i/WIKI_LEN*100, len(kalimat)))\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    dataset = pd.DataFrame({\n",
    "        'kata': kata,\n",
    "        'discourse_id': discourse,\n",
    "        'kalimat': kalimat,\n",
    "    })\n",
    "    dataset.to_csv('../unsupervised dataset/{}.csv'.format(chosen_word), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_words = '''cabang cerah coklat \n",
    "dalam dasar dunia halaman harapan \n",
    "jalan jam jaringan kabur kaki \n",
    "kali kepala ketat kulit kunci \n",
    "layar lebat lingkungan mata membawa \n",
    "memecahkan menangkap mendorong menerima mengandung \n",
    "mengejar mengeluarkan mengikat mengisi menjaga \n",
    "menurunkan menyusun nilai panas pembagian \n",
    "rapat sarung tengah tinggi '''.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cabang\n",
      "Raw read: 100.0 % | Instance collected: 1015\n",
      "cerah\n",
      "Raw read: 100.0 % | Instance collected: 130\n",
      "coklat\n",
      "Raw read: 100.0 % | Instance collected: 268\n",
      "dalam\n",
      "Raw read: 4.4 % | Instance collected: 9967\n",
      "target achieved\n",
      "\n",
      "dasar\n",
      "Raw read: 100.0 % | Instance collected: 3643\n",
      "dunia\n",
      "Raw read: 91.6 % | Instance collected: 9988\n",
      "target achieved\n",
      "\n",
      "halaman\n",
      "Raw read: 1.0 % | Instance collected: 53"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = 10000\n",
    "for w in ambiguous_words:\n",
    "    chosen_word = w\n",
    "    print()\n",
    "    print(w)\n",
    "    execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asing 400\n",
      "cabang 400\n",
      "membawa 400\n",
      "harapan 400\n",
      "kabur 131\n",
      "jam 400\n",
      "tinggi 400\n",
      "menjaga 373\n",
      "halaman 400\n",
      "memecahkan 91\n",
      "mengejar 193\n",
      "kunci 317\n",
      "layar 400\n",
      "mendorong 329\n",
      "menyusun 219\n",
      "rapat 212\n",
      "buah 400\n",
      "lebat 72\n",
      "mata 400\n",
      "kaki 400\n",
      "panas 400\n",
      "cerah 64\n",
      "pembagian 400\n",
      "jaringan 400\n",
      "kali 400\n",
      "jalan 400\n",
      "baru 400\n",
      "ketat 130\n",
      "tengah 400\n",
      "mengandung 400\n",
      "bintang 400\n",
      "menangkap 301\n",
      "bulan 400\n",
      "dasar 400\n",
      "kepala 400\n",
      "berat 400\n",
      "kulit 400\n",
      "dalam 400\n",
      "sarung 54\n",
      "coklat 159\n",
      "lingkungan 400\n",
      "menurunkan 198\n",
      "mengisi 310\n",
      "bidang 400\n",
      "mengeluarkan 400\n",
      "badan 400\n",
      "bisa 400\n",
      "dunia 400\n",
      "bunga 400\n",
      "atas 400\n",
      "besar 400\n",
      "mengikat 117\n",
      "nilai 400\n",
      "menerima 400\n"
     ]
    }
   ],
   "source": [
    "for k in obtained_words:\n",
    "    print(k, len(dataset.query('kata == \"{}\"'.format(k))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../wikipedia_no_annotator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

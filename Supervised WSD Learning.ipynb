{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical-Sample Supervised Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress\n",
    "Classifier: Linear SVM\n",
    "Cross validation: k-fold cross validation\n",
    "\n",
    "### Include PERSON, LOCATION, ORGANIZATION, OTHER ENTITY, and MWE\n",
    "5-fold CV\n",
    "\n",
    "Features, cross validation macro average accuracy:\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .74\n",
    "- It Makes Sense's Local Collocation + Surrounding Words: .726\n",
    "- It Makes Sense's Local Collocation SVD: .721\n",
    "- Latent Semantic Analysis: .713\n",
    "- It Makes Sense's Local Collocation: .71\n",
    "- Surrounding Words SVD: .708\n",
    "- Collocation Vector: .70\n",
    "- TF-IDF: .70\n",
    "- Unigram-Bigram TFIDF: .69\n",
    "- Choose most frequent sense: .57\n",
    "\n",
    "\n",
    "Features, cross validation macro average F1-score:\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .533\n",
    "- It Makes Sense's Local Collocation SVD: .528\n",
    "- It Makes Sense's Local Collocation + Surrounding Words: .526\n",
    "- It Makes Sense's Local Collocation: .524\n",
    "- Collocation Vector SVD: .506\n",
    "- Collocation Vector: .495\n",
    "- Latent Semantic Analysis: .491\n",
    "- Surrounding Words SVD: .477\n",
    "- TF-IDF: .427\n",
    "- Unigram-Bigram TF-IDF: .399\n",
    "- Choose most frequent sense: .220\n",
    "\n",
    "### Pure WSD,  with MWE\n",
    "5-fold CV\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .550\n",
    "- It Makes Sense's Local Collocation SVD: .539\n",
    "- It Makes Sense's Local Collocation: .537\n",
    "- Latent Semantic Analysis: .506\n",
    "- Surrounding Words SVD: .505\n",
    "- Collocation Vector SVD: .505\n",
    "- Collocation Vector: .501\n",
    "- TF-IDF: .434\n",
    "- Choose most frequent sense: .241\n",
    "\n",
    "### Pure WSD,  not even MWE\n",
    "5-fold CV, F1-score\n",
    "- Iacobacci, et. al (2016) replication: .635\n",
    "- Wikipedia word embedding + POS tags SVD + IMS collocation vectors: .635\n",
    "- Wikipedia word embedding + POS tags SVD: .630\n",
    "- Wikipedia word embedding + POS tags SVD + Surrounding words SVD: .630\n",
    "- Wikipedia word embedding + IMS collocation vectors + Surrounding words SVD: .630\n",
    "- Wikipedia word embedding + IMS collocation vectors: .628\n",
    "- Wikipedia word embedding + Surrounding words SVD: .623\n",
    "- Wikipedia word embedding: .618\n",
    "- It Makes Sense's (Zhong & Ng, 2010) Replication, but SVD: .576\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .567\n",
    "- POS Tags SVD + Surrounding Words SVD: .561\n",
    "- It Makes Sense's Local Collocation SVD + POS Tags SVD: .558\n",
    "- It Makes Sense's Local Collocation SVD: .546\n",
    "- It Makes Sense's Local Collocation: .545\n",
    "- Latent Semantic Analysis: .524\n",
    "- Surrounding Words SVD: .520\n",
    "- POS Tags SVD: .488\n",
    "- POS Tags: .488\n",
    "- TF-IDF: .459\n",
    "- Choose most frequent sense: .253\n",
    "\n",
    "In general, training accuracy / f1-score is perfect, but the cross validation score is way too low, which means:\n",
    "**Overfit**\n",
    "\n",
    "- Now with word embedding, the training score is never 100% perfect and the cross validation score *improved drastically*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Tackle overfit problem -> word embedding somewhat solved this\n",
    "- Wikipedia Indonesia Word Embedding -> done\n",
    "- SVD with larger dimension (with extra memory)\n",
    "- Build balanced dataset: manual labor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>clean</th>\n",
       "      <th>targetpos_clean</th>\n",
       "      <th>targetpos_ori</th>\n",
       "      <th>targetpos_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cuaca cerah adalah lazim panjang tahun</td>\n",
       "      <td>NN NN VB NN NN NN Z</td>\n",
       "      <td>cuaca cerah lazim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>gambar yang hasil oleh layarnya cukup cerah da...</td>\n",
       "      <td>NNP SC VB IN NN RB JJ CC VB NN SC JJ VB NN SC ...</td>\n",
       "      <td>gambar hasil layarnya cerah milik speaker hasi...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4803</td>\n",
       "      <td>masa depan yang cerah bagi pemuda umur somenum...</td>\n",
       "      <td>NN NN SC VB IN NN NN CD IN NNP NNP CD Z</td>\n",
       "      <td>cerah bagi pemuda umur prancis abad</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cor caroli alpha canum venaticorum nama lengka...</td>\n",
       "      <td>NNP NNP Z NNP NNP NNP Z Z Z NN RB VB NNP NNP N...</td>\n",
       "      <td>cor caroli alpha canum venaticorum nama lengka...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>sanders lebih suka cat air untuk lilo dengan m...</td>\n",
       "      <td>NN RB VB NN NN SC NNP IN NN VB NN NN NN NN NN Z</td>\n",
       "      <td>sanders suka cat air lilo maksud tampil warna ...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   kata sense                                            kalimat  \\\n",
       "0           0  cerah  4801             cuaca cerah adalah lazim panjang tahun   \n",
       "1           1  cerah  4801  gambar yang hasil oleh layarnya cukup cerah da...   \n",
       "2           2  cerah  4803  masa depan yang cerah bagi pemuda umur somenum...   \n",
       "3           3  cerah  4801  cor caroli alpha canum venaticorum nama lengka...   \n",
       "4           4  cerah  4801  sanders lebih suka cat air untuk lilo dengan m...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0                                NN NN VB NN NN NN Z   \n",
       "1  NNP SC VB IN NN RB JJ CC VB NN SC JJ VB NN SC ...   \n",
       "2            NN NN SC VB IN NN NN CD IN NNP NNP CD Z   \n",
       "3  NNP NNP Z NNP NNP NNP Z Z Z NN RB VB NNP NNP N...   \n",
       "4    NN RB VB NN NN SC NNP IN NN VB NN NN NN NN NN Z   \n",
       "\n",
       "                                               clean  targetpos_clean  \\\n",
       "0                                  cuaca cerah lazim                1   \n",
       "1  gambar hasil layarnya cerah milik speaker hasi...                3   \n",
       "2                cerah bagi pemuda umur prancis abad                0   \n",
       "3  cor caroli alpha canum venaticorum nama lengka...               12   \n",
       "4  sanders suka cat air lilo maksud tampil warna ...                8   \n",
       "\n",
       "   targetpos_ori  targetpos_pos_tag  \n",
       "0              1                  1  \n",
       "1              6                  6  \n",
       "2              3                  3  \n",
       "3             16                 21  \n",
       "4             11                 11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train_data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop rare sense from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RARE_LIMIT = 5\n",
    "sense_set = set(dataset.sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_sense = set(filter(lambda s: len(dataset.query('sense == \"{}\"'.format(s))) <= RARE_LIMIT, sense_set))\n",
    "len(rare_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kata = []\n",
    "dataset_sense = []\n",
    "dataset_kalimat = []\n",
    "dataset_clean = []\n",
    "dataset_pos_clean = []\n",
    "dataset_pos_ori = []\n",
    "dataset_pos_tags = []\n",
    "dataset_pos_pos_tag = []\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    if row.sense not in rare_sense:\n",
    "        dataset_kata.append(row.kata)\n",
    "        dataset_sense.append(row.sense)\n",
    "        dataset_kalimat.append(row.kalimat)\n",
    "        dataset_clean.append(row.clean)\n",
    "        dataset_pos_clean.append(row.targetpos_clean)\n",
    "        dataset_pos_ori.append(row.targetpos_ori)\n",
    "        dataset_pos_tags.append(row.pos_tags)\n",
    "        dataset_pos_pos_tag.append(row.targetpos_pos_tag)\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'kata': dataset_kata,\n",
    "    'sense': dataset_sense,\n",
    "    'kalimat': dataset_kalimat,\n",
    "    'clean': dataset_clean,\n",
    "    'targetpos_clean': dataset_pos_clean,\n",
    "    'targetpos_ori': dataset_pos_ori,\n",
    "    'pos_tags': dataset_pos_tags,\n",
    "    'targetpos_pos_tag': dataset_pos_pos_tag,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4901', '4903', '4904'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset.query('kata == \"{}\"'.format('panas')).sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8311"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGS_WINDOW = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = [['-' for j in range(2*POS_TAGS_WINDOW+1)] for i in range(len(dataset))]\n",
    "possible_tags = set()\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    tags = row.pos_tags.split()\n",
    "    position = row.targetpos_pos_tag\n",
    "    pos_tags[i][POS_TAGS_WINDOW] = tags[position]\n",
    "    j = position-1\n",
    "    k = POS_TAGS_WINDOW - 1\n",
    "    while j >= 0 and j >= position - POS_TAGS_WINDOW:\n",
    "        if tags[j] == 'Z':\n",
    "            break # do not even include\n",
    "        pos_tags[i][k] = tags[j]\n",
    "        k -= 1\n",
    "        j -= 1\n",
    "    j = position+1\n",
    "    k = POS_TAGS_WINDOW + 1\n",
    "    while j < len(tags) and j <= position + POS_TAGS_WINDOW:\n",
    "        pos_tags[i][k] = tags[j]\n",
    "        if tags[j] == 'Z':\n",
    "            break # include, then break\n",
    "\n",
    "        k += 1\n",
    "        j += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_transformer = OneHotEncoder().fit(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pos_tag_transformer.transform(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x98 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41555 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_u = TfidfVectorizer()\n",
    "u_tfidf = tfidf_u.fit_transform(dataset.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x20337 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 99962 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram-Bigram TF-IDF\n",
    "as in Faisal, et. al (2018) \"Word Sense Disambiguation in Bahasa Indonesia using SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_unigram_bigram = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    combined_unigram_bigram.append(row.clean + ' ' + row.clean_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ub = TfidfVectorizer()\n",
    "ub_tfidf = tfidf_ub.fit_transform(combined_unigram_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8721x109586 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 220345 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdtfidf = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))\n",
    "lsa = svdtfidf.fit_transform(u_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 1000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocessor import normalize_money, normalize_number, stemmer, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_WINDOW = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_words = [[] for i in range(len(dataset))]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    tokens = dataset.iloc[i].kalimat.split()\n",
    "    pos = dataset.iloc[i].targetpos_ori\n",
    "    for j in range(max(0, pos-CONTEXT_WINDOW), pos):\n",
    "        token = pipe(normalize_money, normalize_number, stemmer.stem)(tokens[j])\n",
    "        context_words[i].append(token)\n",
    "    for j in range(pos+1, min(len(tokens), pos+CONTEXT_WINDOW+1)):\n",
    "        token = pipe(normalize_money, normalize_number, stemmer.stem)(tokens[j])\n",
    "        context_words[i].append(token)\n",
    "    context_words[i] = ' '.join(context_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "collocation_vector = cv.fit_transform(list(map(lambda s: ' '.join(set(s.split())), context_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8428x7855 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45075 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct implementation of collocation vectors\n",
    "as in Zhong & Ng (2010) \"It Makes Sense\", but unigram and bigrams only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csr import csr_matrix\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_pos = {\n",
    "    (-2, -2), (-1, -1), (1, 1), (2, 2), (-2, -1), (-1, 1), (1, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collocation(sentence, targetpos, L, R):\n",
    "    col = ['-' for i in range(R-L+1 - (1 if L < 0 and R > 0 else 0))]\n",
    "    tokens = sentence.split()\n",
    "    L = targetpos+L\n",
    "    R = targetpos+R\n",
    "    j = L\n",
    "    i = 0\n",
    "    while j <= R:\n",
    "        if j < 0:\n",
    "            j += 1\n",
    "            i += 1\n",
    "            continue\n",
    "        if j == targetpos:\n",
    "            j += 1\n",
    "            continue\n",
    "        if j >= len(tokens):\n",
    "            break\n",
    "        col[i] = tokens[j]\n",
    "        j += 1\n",
    "        i += 1\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masa depan yang cerah bagi pemuda umur somenumber di prancis abad somenumber 3\n"
     ]
    }
   ],
   "source": [
    "print(dataset.iloc[2].kalimat, dataset.iloc[2].targetpos_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_words = [[] for i in range(len(dataset))]\n",
    "collocations = ['' for i in range(len(dataset))]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    instance = dataset.iloc[i]\n",
    "    for l, r in collocation_pos:\n",
    "        collocation_words[i].append(get_collocation(instance.kalimat, instance.targetpos_ori, l, r))\n",
    "        collocations[i] = ' '.join(list(map(lambda s: ' '.join(s) , collocation_words[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_unigram_bigram = CountVectorizer().fit(collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_vectors = [0 for i in range(len(dataset))]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    collocation_vectors[i] = cv_unigram_bigram.transform(\n",
    "        reduce(lambda acc, nex: [*acc, *nex], collocation_words[i], [])\n",
    "    ).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_vectors = csr_matrix([np.array(vec.toarray()[0], dtype=np.bool) for vec in collocation_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x62350 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 80193 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bin = CountVectorizer()\n",
    "surrounding_words = cv_bin.fit_transform(\n",
    "    list(map(lambda s: ' '.join(set(s.split())), dataset.clean))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrounding_words = csr_matrix(np.array([surrounding_words[i].toarray()[0] for i in range(surrounding_words.shape[0])], dtype=np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x20337 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 99962 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrounding_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word2Vec Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('../wikipedia_indonesia_embedding{}.model'.format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Decay Word Embedding Features\n",
    "Iacobacci, et. al (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 %"
     ]
    }
   ],
   "source": [
    "embedding = []\n",
    "\n",
    "W = 5\n",
    "alpha = 1 - (np.power(0.1, np.power(W-1.0, -1)))\n",
    "\n",
    "for p in range(len(dataset)):\n",
    "    if (p % 800) == 0:\n",
    "        sys.stdout.write(\"\\r{0:.2f} %\".format(p/len(dataset)))\n",
    "        sys.stdout.flush()\n",
    "    instance = dataset.iloc[p]\n",
    "    e = np.zeros(EMBEDDING_SIZE)\n",
    "    I = instance.targetpos_ori\n",
    "    words = instance.kalimat.split()\n",
    "    for i in range(EMBEDDING_SIZE):\n",
    "        for j in range(max(0, I-W), min(len(words), I+W+1)):\n",
    "            if j == I:\n",
    "                continue\n",
    "            try:\n",
    "                e[i] += (word_vectors.get_vector(words[j])[i] * (np.power(1 - alpha, abs(I-j) - 1)))\n",
    "            except:\n",
    "                continue\n",
    "    embedding.append(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 50)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It Makes Sense's Collocation Vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = collocation_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x62350 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 80193 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdimscv = make_pipeline(TruncatedSVD(5000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 829.8634827000005\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = svdimscv.fit_transform(collocation_vectors)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "imscvsvd = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imscvsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 5000)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = surrounding_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdsw = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 27.190810500000225\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "swsvd = svdsw.fit_transform(surrounding_words)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = swsvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors SVD + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 9.209585700000162\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 6000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation Vector only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = collocation_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation Vector SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdcv = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 21.836217599999998\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "cvsvd = svdcv.fit_transform(collocation_vector)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cvsvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors + Surrounding Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_imscv_sw = lambda imscv, sw: csr_matrix(\n",
    "    np.array(\n",
    "        list(map(lambda i: [*imscv[i].toarray()[0], *sw[i].toarray()[0]], [i for i in range(imscv.shape[0])])),\n",
    "        dtype=np.bool\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 250.5095411000002\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = transform_to_imscv_sw(\n",
    "    collocation_vectors,\n",
    "    surrounding_words\n",
    ")\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8721x238788 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 301381 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = u_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram-Bigram TF-IDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ub_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpos = make_pipeline(TruncatedSVD(80), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "possvd = svdpos.fit_transform(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = possvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.57551219999732\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 17.504873400001088\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *imscvsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It Makes Sense's Features Set SVD\n",
    "The It Makes Sense's disambiguator system uses collocation vectors, surrounding words, and POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 18.15229390001332\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *imscvsvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.5411793000002945\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.6643506000000343\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*swsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 14.905517000000145\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 37.737581800000044\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 35.42523809999875\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + Surrounding Words SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.7706331999997929\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*swsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iacobacci, et. al Features Set SVD\n",
    "But the word embedding is not transformed by SVD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 17.88977089999935\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_words = set(dataset.kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappers = dict()\n",
    "for w in annotated_words:\n",
    "    possible_sense = set(dataset.query('kata == \"{}\"'.format(w)).sense)\n",
    "    mappers[w] = []\n",
    "    for sense, i in zip(list(possible_sense),  [n for n in range(len(possible_sense))]):\n",
    "        mappers[w].append((sense, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([list(filter(lambda m: m[0] == sense, mappers[kata]))[0][1] for sense, kata in zip(dataset.sense, dataset.kata)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy classifier: always choose the most frequent sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {w: None for w in annotated_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report([0,1,1], [0,1,0], output_dict=True)['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select best parameter using k-fold cross validation\n",
    "'''\n",
    "def train(X, y, clf, possible_param, fold=3):\n",
    "    clf = GridSearchCV(clf, possible_param, cv=fold, n_jobs=7, iid=False)\n",
    "    clf.fit(X, y)\n",
    "    label_counts = np.bincount(y)\n",
    "    most_freq_label = np.argmax(label_counts)\n",
    "    print()\n",
    "    print('Cross validation accuracy:', clf.best_score_)\n",
    "    dummy_score = label_counts[most_freq_label] / len(y)\n",
    "    print('Dummy classifier accuracy: ', dummy_score)\n",
    "    print_param(clf.best_params_)\n",
    "    return (clf.best_estimator_, clf.best_score_, dummy_score)\n",
    "\n",
    "def train_f1(X, y, clf, possible_param, fold=3):\n",
    "    clf = GridSearchCV(clf, possible_param, cv=fold, n_jobs=7, iid=False, scoring='f1_macro')\n",
    "    clf.fit(X, y)\n",
    "    label_counts = np.bincount(y)\n",
    "    most_freq_label = np.argmax(label_counts)\n",
    "    print()\n",
    "    print('Training f1-score:', classification_report(y, clf.predict(X), output_dict=True)['macro avg']['f1-score'])\n",
    "    print('Cross validation f1-score:', clf.best_score_)\n",
    "    dummy_score = classification_report(y, [most_freq_label for i in y], output_dict=True)['macro avg']['f1-score']\n",
    "    print('Dummy classifier f1-score: ', dummy_score)\n",
    "    print_param(clf.best_params_)\n",
    "    return (clf.best_estimator_, clf.best_score_, dummy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(param):\n",
    "    print('Best parameters:')\n",
    "    for p in param:\n",
    "        print(p, ':', param[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(clf, possible_param, fold=5, algorithm_name=''):\n",
    "    print(algorithm_name)\n",
    "    scores = []\n",
    "    dummy_scores = []\n",
    "    for w in classifier.keys():\n",
    "        print('==================================')\n",
    "        print(w)\n",
    "        indexes = list(dataset.query('kata == \"{}\"'.format(w)).index)\n",
    "        best_clf, best_score, dummy_score = train(X_train[indexes], y_train[indexes], clf, possible_param, fold)\n",
    "        scores.append(best_score)\n",
    "        dummy_scores.append(dummy_score)\n",
    "        classifier[w] = best_clf\n",
    "        print('----------------------------------')\n",
    "    print('Cross validation macro average accuracy:', sum(scores)/len(scores))\n",
    "    print('Dummy classifier macro average accuracy:', sum(dummy_scores)/len(dummy_scores))\n",
    "\n",
    "def train_all_f1(clf, possible_param, fold=5, algorithm_name=''):\n",
    "    print(algorithm_name)\n",
    "    scores = []\n",
    "    dummy_scores = []\n",
    "    for w in classifier.keys():\n",
    "        print('==================================')\n",
    "        print(w)\n",
    "        indexes = list(dataset.query('kata == \"{}\"'.format(w)).index)\n",
    "        best_clf, best_score, dummy_score = train_f1(X_train[indexes], y_train[indexes], clf, possible_param, fold)\n",
    "        scores.append(best_score)\n",
    "        dummy_scores.append(dummy_score)\n",
    "        classifier[w] = best_clf\n",
    "        print('----------------------------------')\n",
    "    print('Cross validation macro average f1-score:', sum(scores)/len(scores))\n",
    "    print('Dummy classifier macro average f1-score:', sum(dummy_scores)/len(dummy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 3, 1, 2, 1, 2, 3, 2, 1, 3, 1,\n",
       "       1, 3, 1, 2, 1, 1, 2, 2, 3, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 3, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "       0, 1, 3, 2, 2, 2, 1, 2, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1,\n",
       "       3, 2, 2, 2, 1, 1, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 0, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1,\n",
       "       2, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[list(dataset.query('kata == \"{}\"'.format('besar')).index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_all(\n",
    "    LogisticRegression(),\n",
    "    {'solver':['newton-cg'], 'max_iter':[10, 20, 50], 'multi_class': ['ovr', 'multinomial']},\n",
    "    algorithm_name='Logistic Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "==================================\n",
      "dunia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9104030501089325\n",
      "Cross validation f1-score: 0.38233029422684595\n",
      "Dummy classifier f1-score:  0.1794871794871795\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "tinggi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9730847574139373\n",
      "Cross validation f1-score: 0.5534184528921371\n",
      "Dummy classifier f1-score:  0.10232558139534884\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengandung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9653404067197171\n",
      "Cross validation f1-score: 0.7947705627705627\n",
      "Dummy classifier f1-score:  0.4895833333333333\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menangkap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9163043788856641\n",
      "Cross validation f1-score: 0.6407743798342511\n",
      "Dummy classifier f1-score:  0.29508196721311475\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "baru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.6709933869987663\n",
      "Dummy classifier f1-score:  0.284037558685446\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "asing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.7210493317934334\n",
      "Dummy classifier f1-score:  0.4825174825174825\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "bunga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.8916200326284359\n",
      "Dummy classifier f1-score:  0.4703703703703704\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengikat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.5530685567156155\n",
      "Dummy classifier f1-score:  0.13793103448275862\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "dalam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.924966197861665\n",
      "Cross validation f1-score: 0.2839214109053926\n",
      "Dummy classifier f1-score:  0.07039337474120083\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "mengejar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9261075623325777\n",
      "Cross validation f1-score: 0.7714690303216283\n",
      "Dummy classifier f1-score:  0.38257575757575757\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mendorong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9752120890774125\n",
      "Cross validation f1-score: 0.7339248582714284\n",
      "Dummy classifier f1-score:  0.4672364672364672\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.784333400517611\n",
      "Dummy classifier f1-score:  0.14371257485029942\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "memecahkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.8227867793033079\n",
      "Dummy classifier f1-score:  0.2164821648216482\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "kepala\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.6550142938822184\n",
      "Dummy classifier f1-score:  0.3046964490263459\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "bintang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9553164520496643\n",
      "Cross validation f1-score: 0.7293726112116916\n",
      "Dummy classifier f1-score:  0.24113475177304963\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengeluarkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.973581064880461\n",
      "Cross validation f1-score: 0.46292868559281003\n",
      "Dummy classifier f1-score:  0.13970588235294118\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "badan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.766682635365431\n",
      "Dummy classifier f1-score:  0.27255985267034993\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "menerima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9315421793839059\n",
      "Cross validation f1-score: 0.24484964545609705\n",
      "Dummy classifier f1-score:  0.11327433628318584\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9684419889502762\n",
      "Cross validation f1-score: 0.775521181901026\n",
      "Dummy classifier f1-score:  0.2309711286089239\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "jam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9429552091629689\n",
      "Cross validation f1-score: 0.7081064326796034\n",
      "Dummy classifier f1-score:  0.17924528301886794\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "pembagian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9614120983148714\n",
      "Cross validation f1-score: 0.420010390595068\n",
      "Dummy classifier f1-score:  0.1721698113207547\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "coklat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9914311524067622\n",
      "Cross validation f1-score: 0.6718004090939068\n",
      "Dummy classifier f1-score:  0.3037974683544304\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "menjaga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8191020622717844\n",
      "Cross validation f1-score: 0.3628626129530929\n",
      "Dummy classifier f1-score:  0.1634980988593156\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "panas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.93\n",
      "Cross validation f1-score: 0.6852729121942936\n",
      "Dummy classifier f1-score:  0.23008849557522124\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "halaman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.98355792863802\n",
      "Cross validation f1-score: 0.66859588355244\n",
      "Dummy classifier f1-score:  0.24637681159420288\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "layar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.8943768756870734\n",
      "Dummy classifier f1-score:  0.3347826086956522\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "sarung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9945528431852898\n",
      "Cross validation f1-score: 0.9238178079992126\n",
      "Dummy classifier f1-score:  0.37\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "jalan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.43096046401928756\n",
      "Dummy classifier f1-score:  0.1651376146788991\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "lebat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9880704041720991\n",
      "Cross validation f1-score: 0.9221115348037102\n",
      "Dummy classifier f1-score:  0.3920265780730897\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "bulan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.990195561646724\n",
      "Cross validation f1-score: 0.8683471614283628\n",
      "Dummy classifier f1-score:  0.45614035087719296\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "atas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.913350069614272\n",
      "Cross validation f1-score: 0.5064914757462302\n",
      "Dummy classifier f1-score:  0.05970149253731344\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "nilai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.6140097892303773\n",
      "Dummy classifier f1-score:  0.12085308056872036\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "berat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9378286605790851\n",
      "Cross validation f1-score: 0.42319548872180446\n",
      "Dummy classifier f1-score:  0.10769230769230768\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "jaringan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9087839959801519\n",
      "Cross validation f1-score: 0.7248255445970156\n",
      "Dummy classifier f1-score:  0.20202020202020202\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "ketat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9681185451279748\n",
      "Cross validation f1-score: 0.6892955970578166\n",
      "Dummy classifier f1-score:  0.1534090909090909\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "rapat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.8676418801676451\n",
      "Dummy classifier f1-score:  0.45964912280701753\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menurunkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8219997867056691\n",
      "Cross validation f1-score: 0.4109270118093648\n",
      "Dummy classifier f1-score:  0.12656641604010024\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "lingkungan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9102564102564102\n",
      "Cross validation f1-score: 0.5601901440407188\n",
      "Dummy classifier f1-score:  0.2222222222222222\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kaki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9911490437806227\n",
      "Cross validation f1-score: 0.9017498926194578\n",
      "Dummy classifier f1-score:  0.24444444444444446\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "bisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.945285784074255\n",
      "Cross validation f1-score: 0.5412114400349695\n",
      "Dummy classifier f1-score:  0.43718592964824116\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "cerah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.8179616923956546\n",
      "Dummy classifier f1-score:  0.47586206896551725\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "kunci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.980952380952381\n",
      "Cross validation f1-score: 0.45161749470429163\n",
      "Dummy classifier f1-score:  0.14832535885167464\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "cabang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.6893024029704358\n",
      "Dummy classifier f1-score:  0.3177570093457944\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menyusun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.5695140404154191\n",
      "Dummy classifier f1-score:  0.24242424242424243\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "besar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9753411064252047\n",
      "Cross validation f1-score: 0.47418820455153216\n",
      "Dummy classifier f1-score:  0.15732758620689655\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "tengah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.6282568542568543\n",
      "Dummy classifier f1-score:  0.1624203821656051\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "mengisi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7649615515476323\n",
      "Cross validation f1-score: 0.4486876305955253\n",
      "Dummy classifier f1-score:  0.14791666666666667\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "kulit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9912157540411132\n",
      "Cross validation f1-score: 0.685864050369827\n",
      "Dummy classifier f1-score:  0.26506024096385544\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "dasar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.819662955376415\n",
      "Cross validation f1-score: 0.47968253968253977\n",
      "Dummy classifier f1-score:  0.176056338028169\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "buah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9913194444444445\n",
      "Cross validation f1-score: 0.8649261247047091\n",
      "Dummy classifier f1-score:  0.2397003745318352\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "bidang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.7370020964360587\n",
      "Dummy classifier f1-score:  0.4854014598540146\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kabur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 1.0\n",
      "Cross validation f1-score: 0.4885371744775493\n",
      "Dummy classifier f1-score:  0.3182674199623352\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "membawa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9373365959681467\n",
      "Cross validation f1-score: 0.31478238847986745\n",
      "Dummy classifier f1-score:  0.05442176870748299\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "harapan\n",
      "\n",
      "Training f1-score: 0.958223626470072\n",
      "Cross validation f1-score: 0.5829935145420114\n",
      "Dummy classifier f1-score:  0.2818428184281843\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "Cross validation macro average f1-score: 0.6345916016333781\n",
      "Dummy classifier macro average f1-score: 0.2526642298604586\n",
      "elapsed time: 256.5487159000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\yerla\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "train_all_f1(\n",
    "    LinearSVC(),\n",
    "    {'max_iter': [10, 20, 40], 'C':[0.25, 0.5, 1.0, 2.0, 4.0, 8.0]},\n",
    "    algorithm_name='Linear SVM'\n",
    ")\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.84,\n",
       "  'recall': 0.9130434782608695,\n",
       "  'f1-score': 0.8749999999999999,\n",
       "  'support': 46},\n",
       " '1': {'precision': 0.9433962264150944,\n",
       "  'recall': 0.8064516129032258,\n",
       "  'f1-score': 0.8695652173913043,\n",
       "  'support': 62},\n",
       " '2': {'precision': 0.8181818181818182,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9,\n",
       "  'support': 27},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.9166666666666666,\n",
       "  'f1-score': 0.9565217391304348,\n",
       "  'support': 12},\n",
       " 'accuracy': 0.8843537414965986,\n",
       " 'macro avg': {'precision': 0.9003945111492282,\n",
       "  'recall': 0.9090404394576904,\n",
       "  'f1-score': 0.9002717391304347,\n",
       "  'support': 147},\n",
       " 'weighted avg': {'precision': 0.892663096113231,\n",
       "  'recall': 0.8843537414965986,\n",
       "  'f1-score': 0.8839544513457556,\n",
       "  'support': 147}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(\n",
    "    y_train[list(dataset.query('kata == \"{}\"'.format('kunci')).index)], \n",
    "    classifier['kunci'].predict(X_train[list(dataset.query('kata == \"{}\"'.format('kunci')).index)]),\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

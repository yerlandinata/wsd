{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical-Sample Supervised Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress\n",
    "Classifier: Linear SVM\n",
    "Cross validation: k-fold cross validation\n",
    "\n",
    "### Include PERSON, LOCATION, ORGANIZATION, OTHER ENTITY, and MWE\n",
    "5-fold CV\n",
    "\n",
    "Features, cross validation macro average accuracy:\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .74\n",
    "- It Makes Sense's Local Collocation + Surrounding Words: .726\n",
    "- It Makes Sense's Local Collocation SVD: .721\n",
    "- Latent Semantic Analysis: .713\n",
    "- It Makes Sense's Local Collocation: .71\n",
    "- Surrounding Words SVD: .708\n",
    "- Collocation Vector: .70\n",
    "- TF-IDF: .70\n",
    "- Unigram-Bigram TFIDF: .69\n",
    "- Choose most frequent sense: .57\n",
    "\n",
    "\n",
    "Features, cross validation macro average F1-score:\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .533\n",
    "- It Makes Sense's Local Collocation SVD: .528\n",
    "- It Makes Sense's Local Collocation + Surrounding Words: .526\n",
    "- It Makes Sense's Local Collocation: .524\n",
    "- Collocation Vector SVD: .506\n",
    "- Collocation Vector: .495\n",
    "- Latent Semantic Analysis: .491\n",
    "- Surrounding Words SVD: .477\n",
    "- TF-IDF: .427\n",
    "- Unigram-Bigram TF-IDF: .399\n",
    "- Choose most frequent sense: .220\n",
    "\n",
    "### Pure WSD,  with MWE\n",
    "5-fold CV\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .550\n",
    "- It Makes Sense's Local Collocation SVD: .539\n",
    "- It Makes Sense's Local Collocation: .537\n",
    "- Latent Semantic Analysis: .506\n",
    "- Surrounding Words SVD: .505\n",
    "- Collocation Vector SVD: .505\n",
    "- Collocation Vector: .501\n",
    "- TF-IDF: .434\n",
    "- Choose most frequent sense: .241\n",
    "\n",
    "### Pure WSD,  not even MWE\n",
    "5-fold CV, F1-score\n",
    "- Iacobacci, et. al (2016) replication: .634\n",
    "- Wikipedia word embedding + POS tags SVD + IMS collocation vectors: .630\n",
    "- Wikipedia word embedding + POS tags SVD: .630\n",
    "- Wikipedia word embedding + POS tags SVD + Surrounding words SVD: .630\n",
    "- Wikipedia word embedding + IMS collocation vectors + Surrounding words SVD: .629\n",
    "- Wikipedia word embedding + IMS collocation vectors: .625\n",
    "- Wikipedia word embedding + Surrounding words SVD: .623\n",
    "- Wikipedia word embedding: .618\n",
    "- It Makes Sense's (Zhong & Ng, 2010) Replication, but SVD: .584\n",
    "- It Makes Sense's Local Collocation SVD + Surrounding Words SVD: .582\n",
    "- It Makes Sense's Local Collocation SVD + POS Tags SVD: .574\n",
    "- It Makes Sense's Local Collocation SVD: .573\n",
    "- POS Tags SVD + Surrounding Words SVD: .561\n",
    "- It Makes Sense's Local Collocation: .569\n",
    "- Latent Semantic Analysis: .524\n",
    "- Surrounding Words SVD: .521\n",
    "- POS Tags SVD: .488\n",
    "- POS Tags: .488\n",
    "- TF-IDF: .459\n",
    "- Choose most frequent sense: .253\n",
    "\n",
    "In general, training accuracy / f1-score is perfect, but the cross validation score is way too low, which means:\n",
    "**Overfit**\n",
    "\n",
    "- Now with word embedding, the training score is never 100% perfect and the cross validation score *improved drastically*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Tackle overfit problem -> word embedding somewhat solved this\n",
    "- Wikipedia Indonesia Word Embedding -> done\n",
    "- SVD with larger dimension (with extra memory)\n",
    "- Build balanced dataset: manual labor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>clean</th>\n",
       "      <th>targetpos_clean</th>\n",
       "      <th>targetpos_ori</th>\n",
       "      <th>targetpos_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cuaca cerah adalah lazim panjang tahun</td>\n",
       "      <td>NN NN VB NN NN NN Z</td>\n",
       "      <td>cuaca cerah lazim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>gambar yang hasil oleh layarnya cukup cerah da...</td>\n",
       "      <td>NNP SC VB IN NN RB JJ CC VB NN SC JJ VB NN SC ...</td>\n",
       "      <td>gambar hasil layarnya cerah milik speaker hasi...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4803</td>\n",
       "      <td>masa depan yang cerah bagi pemuda umur somenum...</td>\n",
       "      <td>NN NN SC VB IN NN NN CD IN NNP NNP CD Z</td>\n",
       "      <td>cerah bagi pemuda umur prancis abad</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cor caroli alpha canum venaticorum nama lengka...</td>\n",
       "      <td>NNP NNP Z NNP NNP NNP Z Z Z NN RB VB NNP NNP N...</td>\n",
       "      <td>cor caroli alpha canum venaticorum nama lengka...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>sanders lebih suka cat air untuk lilo dengan m...</td>\n",
       "      <td>NN RB VB NN NN SC NNP IN NN VB NN NN NN NN NN Z</td>\n",
       "      <td>sanders suka cat air lilo maksud tampil warna ...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   kata sense                                            kalimat  \\\n",
       "0           0  cerah  4801             cuaca cerah adalah lazim panjang tahun   \n",
       "1           1  cerah  4801  gambar yang hasil oleh layarnya cukup cerah da...   \n",
       "2           2  cerah  4803  masa depan yang cerah bagi pemuda umur somenum...   \n",
       "3           3  cerah  4801  cor caroli alpha canum venaticorum nama lengka...   \n",
       "4           4  cerah  4801  sanders lebih suka cat air untuk lilo dengan m...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0                                NN NN VB NN NN NN Z   \n",
       "1  NNP SC VB IN NN RB JJ CC VB NN SC JJ VB NN SC ...   \n",
       "2            NN NN SC VB IN NN NN CD IN NNP NNP CD Z   \n",
       "3  NNP NNP Z NNP NNP NNP Z Z Z NN RB VB NNP NNP N...   \n",
       "4    NN RB VB NN NN SC NNP IN NN VB NN NN NN NN NN Z   \n",
       "\n",
       "                                               clean  targetpos_clean  \\\n",
       "0                                  cuaca cerah lazim                1   \n",
       "1  gambar hasil layarnya cerah milik speaker hasi...                3   \n",
       "2                cerah bagi pemuda umur prancis abad                0   \n",
       "3  cor caroli alpha canum venaticorum nama lengka...               12   \n",
       "4  sanders suka cat air lilo maksud tampil warna ...                8   \n",
       "\n",
       "   targetpos_ori  targetpos_pos_tag  \n",
       "0              1                  1  \n",
       "1              6                  6  \n",
       "2              3                  3  \n",
       "3             16                 21  \n",
       "4             11                 11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train_data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop rare sense from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RARE_LIMIT = 5\n",
    "sense_set = set(dataset.sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_sense = set(filter(lambda s: len(dataset.query('sense == \"{}\"'.format(s))) <= RARE_LIMIT, sense_set))\n",
    "len(rare_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kata = []\n",
    "dataset_sense = []\n",
    "dataset_kalimat = []\n",
    "dataset_clean = []\n",
    "dataset_pos_clean = []\n",
    "dataset_pos_ori = []\n",
    "dataset_pos_tags = []\n",
    "dataset_pos_pos_tag = []\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    if row.sense not in rare_sense:\n",
    "        dataset_kata.append(row.kata)\n",
    "        dataset_sense.append(row.sense)\n",
    "        dataset_kalimat.append(row.kalimat)\n",
    "        dataset_clean.append(row.clean)\n",
    "        dataset_pos_clean.append(row.targetpos_clean)\n",
    "        dataset_pos_ori.append(row.targetpos_ori)\n",
    "        dataset_pos_tags.append(row.pos_tags)\n",
    "        dataset_pos_pos_tag.append(row.targetpos_pos_tag)\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'kata': dataset_kata,\n",
    "    'sense': dataset_sense,\n",
    "    'kalimat': dataset_kalimat,\n",
    "    'clean': dataset_clean,\n",
    "    'targetpos_clean': dataset_pos_clean,\n",
    "    'targetpos_ori': dataset_pos_ori,\n",
    "    'pos_tags': dataset_pos_tags,\n",
    "    'targetpos_pos_tag': dataset_pos_pos_tag,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4901', '4903', '4904'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset.query('kata == \"{}\"'.format('panas')).sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGS_WINDOW = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = [['-' for j in range(2*POS_TAGS_WINDOW+1)] for i in range(len(dataset))]\n",
    "possible_tags = set()\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    tags = row.pos_tags.split()\n",
    "    position = row.targetpos_pos_tag\n",
    "    pos_tags[i][POS_TAGS_WINDOW] = tags[position]\n",
    "    j = position-1\n",
    "    k = POS_TAGS_WINDOW - 1\n",
    "    while j >= 0 and j >= position - POS_TAGS_WINDOW:\n",
    "        if tags[j] == 'Z':\n",
    "            break # do not even include\n",
    "        pos_tags[i][k] = tags[j]\n",
    "        k -= 1\n",
    "        j -= 1\n",
    "    j = position+1\n",
    "    k = POS_TAGS_WINDOW + 1\n",
    "    while j < len(tags) and j <= position + POS_TAGS_WINDOW:\n",
    "        pos_tags[i][k] = tags[j]\n",
    "        if tags[j] == 'Z':\n",
    "            break # include, then break\n",
    "\n",
    "        k += 1\n",
    "        j += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGSET = [\n",
    "    '-', 'CC', 'CD', 'DT', 'FW', 'IN', 'JJ', 'MD', 'NEG', 'NN',\n",
    "    'NND','NNP','OD','PR','PRP','RB','RP','SC','SYM','VB','WH','X','Z'\n",
    "]\n",
    "\n",
    "TAG_LABEL = {t: [1 if t == x else 0 for x in TAGSET] for t,i in zip(TAGSET, range(len(TAGSET)))}\n",
    "\n",
    "class POSTagTransformer(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X, y=None):\n",
    "        res = []\n",
    "        for sentence in X:\n",
    "            r = []\n",
    "            for tag in sentence:\n",
    "                r = [*r, *TAG_LABEL[tag]]\n",
    "            res.append(r)\n",
    "        return csr_matrix(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = POSTagTransformer().transform(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_u = TfidfVectorizer()\n",
    "u_tfidf = tfidf_u.fit_transform(dataset.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x20337 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 99962 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram-Bigram TF-IDF\n",
    "as in Faisal, et. al (2018) \"Word Sense Disambiguation in Bahasa Indonesia using SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_unigram_bigram = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset.iloc[i]\n",
    "    combined_unigram_bigram.append(row.clean + ' ' + row.clean_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ub = TfidfVectorizer()\n",
    "ub_tfidf = tfidf_ub.fit_transform(combined_unigram_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8721x109586 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 220345 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdtfidf = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))\n",
    "lsa = svdtfidf.fit_transform(u_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 1000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct (ed again) implementation of collocation vectors\n",
    "as in Zhong & Ng (2010) \"It Makes Sense\", but unigram and bigrams only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocessor import normalize_money, normalize_number, stemmer, pipe\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIGRAM = 0\n",
    "BIGRAM = 1\n",
    "\n",
    "collocation_pos = [\n",
    "    (-2, -2), (-1, -1), (1, 1), (2, 2), (-2, -1), (-1, 1), (1, 2),\n",
    "]\n",
    "\n",
    "collocation_type = [\n",
    "    UNIGRAM, UNIGRAM, UNIGRAM, UNIGRAM, BIGRAM, BIGRAM, BIGRAM\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collocation(sentence, targetpos, L, R):\n",
    "    col = ['-' for i in range(R-L+1 - (1 if L < 0 and R > 0 else 0))]\n",
    "    tokens = sentence.split()\n",
    "    L = targetpos+L\n",
    "    R = targetpos+R\n",
    "    j = L\n",
    "    i = 0\n",
    "    while j <= R:\n",
    "        if j < 0:\n",
    "            j += 1\n",
    "            i += 1\n",
    "            continue\n",
    "        if j == targetpos:\n",
    "            j += 1\n",
    "            continue\n",
    "        if j >= len(tokens):\n",
    "            break\n",
    "        col[i] = tokens[j]\n",
    "        j += 1\n",
    "        i += 1\n",
    "    \n",
    "    return ' '.join(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masa depan yang cerah bagi pemuda umur somenumber di prancis abad somenumber 3\n"
     ]
    }
   ],
   "source": [
    "print(dataset.iloc[2].kalimat, dataset.iloc[2].targetpos_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- masa depan yang cerah bagi'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_collocation(dataset.iloc[2].kalimat, 5, -6, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_words = [[] for i in range(len(dataset))]\n",
    "context_window = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    instance = dataset.iloc[i]\n",
    "    for l, r in collocation_pos:\n",
    "        collocation_words[i].append(get_collocation(instance.kalimat, instance.targetpos_ori, l, r))\n",
    "    context_window.append(get_collocation(instance.kalimat, instance.targetpos_ori, -2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_vectorizer = CountVectorizer(ngram_range=(1,1), min_df=.0002).fit(context_window)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), min_df=.0002).fit(context_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2367\n",
      "2060\n"
     ]
    }
   ],
   "source": [
    "print(len(unigram_vectorizer.vocabulary_))\n",
    "print(len(bigram_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collocation_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_vectors = []\n",
    "\n",
    "vectorizer = [None, None]\n",
    "vectorizer[UNIGRAM] = unigram_vectorizer\n",
    "vectorizer[BIGRAM] = bigram_vectorizer\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    vec = []\n",
    "    for j in range(len(collocation_pos)):\n",
    "        vec = [\n",
    "            *vec, \n",
    "            *vectorizer[collocation_type[j]].transform([collocation_words[i][j]]).toarray()[0]\n",
    "        ]\n",
    "    collocation_vectors.append(vec)\n",
    "        \n",
    "collocation_vectors = csr_matrix(collocation_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x15648 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34988 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bin = CountVectorizer(min_df=.0002)\n",
    "surrounding_words = cv_bin.fit_transform(\n",
    "    list(map(lambda s: ' '.join(set(s.split())), dataset.clean))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrounding_words = csr_matrix(np.array([surrounding_words[i].toarray()[0] for i in range(surrounding_words.shape[0])], dtype=np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x7202 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 86827 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrounding_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word2Vec Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word_vectors = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('../wikipedia_indonesia_embedding{}.model'.format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Decay Word Embedding Features\n",
    "Iacobacci, et. al (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 %"
     ]
    }
   ],
   "source": [
    "embedding = []\n",
    "\n",
    "W = 5\n",
    "alpha = 1 - (np.power(0.1, np.power(W-1.0, -1)))\n",
    "\n",
    "for p in range(len(dataset)):\n",
    "    if (p % 800) == 0:\n",
    "        sys.stdout.write(\"\\r{0:.2f} %\".format(p/len(dataset)))\n",
    "        sys.stdout.flush()\n",
    "    instance = dataset.iloc[p]\n",
    "    e = np.zeros(EMBEDDING_SIZE)\n",
    "    I = instance.targetpos_ori\n",
    "    words = instance.kalimat.split()\n",
    "    for i in range(EMBEDDING_SIZE):\n",
    "        for j in range(max(0, I-W), min(len(words), I+W+1)):\n",
    "            if j == I:\n",
    "                continue\n",
    "            try:\n",
    "                e[i] += (word_vectors.get_vector(words[j])[i] * (np.power(1 - alpha, abs(I-j) - 1)))\n",
    "            except:\n",
    "                continue\n",
    "    embedding.append(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It Makes Sense's Collocation Vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = collocation_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8311x15648 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdimscv = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 12.89343769300001\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = svdimscv.fit_transform(collocation_vectors)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imscvsvd = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imscvsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = surrounding_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdsw = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 12.8981895\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "swsvd = svdsw.fit_transform(surrounding_words)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = swsvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors SVD + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.334622258997115\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311, 2000)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation Vector only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = collocation_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation Vector SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdcv = make_pipeline(TruncatedSVD(1000), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 21.836217599999998\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "cvsvd = svdcv.fit_transform(collocation_vector)\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cvsvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors + Surrounding Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_imscv_sw = lambda imscv, sw: csr_matrix(\n",
    "    np.array(\n",
    "        list(map(lambda i: [*imscv[i].toarray()[0], *sw[i].toarray()[0]], [i for i in range(imscv.shape[0])])),\n",
    "        dtype=np.bool\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 250.5095411000002\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = transform_to_imscv_sw(\n",
    "    collocation_vectors,\n",
    "    surrounding_words\n",
    ")\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8721x238788 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 301381 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = u_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram-Bigram TF-IDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ub_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpos = make_pipeline(TruncatedSVD(80), Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "possvd = svdpos.fit_transform(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = possvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Words SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.57551219999732\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMS Collocation Vectors + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.5660946600037278\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *imscvsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It Makes Sense's Features Set SVD\n",
    "The It Makes Sense's disambiguator system uses collocation vectors, surrounding words, and POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.635862696000004\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *imscvsvd[i], *swsvd[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.5411793000002945\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.381767138998839\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*swsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.319250854998245\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD + Surrounding Words SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.5495485010033008\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + IMS Collocation Vectors SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.5257597589952638\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Word Embedding + Surrounding Words SVD + POS Tags SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.7236650740014738\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*swsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iacobacci, et. al Features Set SVD\n",
    "But the word embedding is not transformed by SVD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.417027671000028\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "X_train = np.array(list(map(lambda i: [*imscvsvd[i], *swsvd[i], *possvd[i], *embedding[i]], [i for i in range(len(dataset))])))\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_words = set(dataset.kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappers = dict()\n",
    "for w in annotated_words:\n",
    "    possible_sense = set(dataset.query('kata == \"{}\"'.format(w)).sense)\n",
    "    mappers[w] = []\n",
    "    for sense, i in zip(list(possible_sense),  [n for n in range(len(possible_sense))]):\n",
    "        mappers[w].append((sense, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([list(filter(lambda m: m[0] == sense, mappers[kata]))[0][1] for sense, kata in zip(dataset.sense, dataset.kata)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy classifier: always choose the most frequent sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {w: None for w in annotated_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report([0,1,1], [0,1,0], output_dict=True)['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select best parameter using k-fold cross validation\n",
    "'''\n",
    "def train(X, y, clf, possible_param, fold=3):\n",
    "    clf = GridSearchCV(clf, possible_param, cv=fold, n_jobs=7, iid=False)\n",
    "    clf.fit(X, y)\n",
    "    label_counts = np.bincount(y)\n",
    "    most_freq_label = np.argmax(label_counts)\n",
    "    print()\n",
    "    print('Cross validation accuracy:', clf.best_score_)\n",
    "    dummy_score = label_counts[most_freq_label] / len(y)\n",
    "    print('Dummy classifier accuracy: ', dummy_score)\n",
    "    print_param(clf.best_params_)\n",
    "    return (clf.best_estimator_, clf.best_score_, dummy_score)\n",
    "\n",
    "def train_f1(X, y, clf, possible_param, fold=3):\n",
    "    clf = GridSearchCV(clf, possible_param, cv=fold, n_jobs=7, iid=False, scoring='f1_macro')\n",
    "    clf.fit(X, y)\n",
    "    label_counts = np.bincount(y)\n",
    "    most_freq_label = np.argmax(label_counts)\n",
    "    print()\n",
    "    print('Training f1-score:', classification_report(y, clf.predict(X), output_dict=True)['macro avg']['f1-score'])\n",
    "    print('Cross validation f1-score:', clf.best_score_)\n",
    "    dummy_score = classification_report(y, [most_freq_label for i in y], output_dict=True)['macro avg']['f1-score']\n",
    "    print('Dummy classifier f1-score: ', dummy_score)\n",
    "    print_param(clf.best_params_)\n",
    "    return (clf.best_estimator_, clf.best_score_, dummy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(param):\n",
    "    print('Best parameters:')\n",
    "    for p in param:\n",
    "        print(p, ':', param[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(clf, possible_param, fold=5, algorithm_name=''):\n",
    "    print(algorithm_name)\n",
    "    scores = []\n",
    "    dummy_scores = []\n",
    "    for w in classifier.keys():\n",
    "        print('==================================')\n",
    "        print(w)\n",
    "        indexes = list(dataset.query('kata == \"{}\"'.format(w)).index)\n",
    "        best_clf, best_score, dummy_score = train(X_train[indexes], y_train[indexes], clf, possible_param, fold)\n",
    "        scores.append(best_score)\n",
    "        dummy_scores.append(dummy_score)\n",
    "        classifier[w] = best_clf\n",
    "        print('----------------------------------')\n",
    "    print('Cross validation macro average accuracy:', sum(scores)/len(scores))\n",
    "    print('Dummy classifier macro average accuracy:', sum(dummy_scores)/len(dummy_scores))\n",
    "\n",
    "def train_all_f1(clf, possible_param, fold=5, algorithm_name=''):\n",
    "    print(algorithm_name)\n",
    "    scores = []\n",
    "    dummy_scores = []\n",
    "    for w in classifier.keys():\n",
    "        print('==================================')\n",
    "        print(w)\n",
    "        indexes = list(dataset.query('kata == \"{}\"'.format(w)).index)\n",
    "        best_clf, best_score, dummy_score = train_f1(X_train[indexes], y_train[indexes], clf, possible_param, fold)\n",
    "        scores.append(best_score)\n",
    "        dummy_scores.append(dummy_score)\n",
    "        classifier[w] = best_clf\n",
    "        print('----------------------------------')\n",
    "    print('Cross validation macro average f1-score:', sum(scores)/len(scores))\n",
    "    print('Dummy classifier macro average f1-score:', sum(dummy_scores)/len(dummy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 3, 2, 3, 1, 3, 1, 2, 1, 3, 2, 3,\n",
       "       3, 2, 3, 1, 3, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3,\n",
       "       3, 3, 3, 1, 1, 1, 1, 3, 1, 1, 1, 3, 0, 1, 1, 3, 1, 3, 1, 3, 3, 3,\n",
       "       3, 3, 3, 1, 1, 1, 3, 2, 0, 3, 3, 3, 3, 1, 3, 1, 1, 1, 1, 1, 1, 3,\n",
       "       0, 3, 2, 1, 1, 1, 3, 1, 3, 0, 3, 1, 1, 3, 3, 1, 0, 1, 3, 3, 3, 3,\n",
       "       2, 1, 1, 1, 3, 3, 3, 3, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 3, 3,\n",
       "       3, 3, 1, 0, 1, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 3, 3, 3, 1, 3, 3, 3,\n",
       "       1, 3, 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[list(dataset.query('kata == \"{}\"'.format('besar')).index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "==================================\n",
      "menurunkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.5984190319484437\n",
      "Cross validation f1-score: 0.3432512604984799\n",
      "Dummy classifier f1-score:  0.12656641604010024\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "bisa\n",
      "\n",
      "Training f1-score: 0.755364255428498\n",
      "Cross validation f1-score: 0.6488748488748489\n",
      "Dummy classifier f1-score:  0.43718592964824116\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "rapat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8897243107769424\n",
      "Cross validation f1-score: 0.6799967673651884\n",
      "Dummy classifier f1-score:  0.45964912280701753\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "bunga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7537878787878788\n",
      "Cross validation f1-score: 0.5461715554146187\n",
      "Dummy classifier f1-score:  0.4703703703703704\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "kabur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8332076525624913\n",
      "Cross validation f1-score: 0.41144800793012315\n",
      "Dummy classifier f1-score:  0.3182674199623352\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "ketat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.595948985654868\n",
      "Cross validation f1-score: 0.39016446613131667\n",
      "Dummy classifier f1-score:  0.1534090909090909\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "dalam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6843445295987773\n",
      "Cross validation f1-score: 0.21476567600577753\n",
      "Dummy classifier f1-score:  0.07039337474120083\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "berat\n",
      "\n",
      "Training f1-score: 0.891305753070459\n",
      "Cross validation f1-score: 0.3518450046685341\n",
      "Dummy classifier f1-score:  0.10769230769230768\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "cabang\n",
      "\n",
      "Training f1-score: 0.6032480429956771\n",
      "Cross validation f1-score: 0.34421304761075555\n",
      "Dummy classifier f1-score:  0.3177570093457944\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "pembagian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.5936671867050225\n",
      "Cross validation f1-score: 0.28113669590643275\n",
      "Dummy classifier f1-score:  0.1721698113207547\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "kulit\n",
      "\n",
      "Training f1-score: 0.6928605257318483\n",
      "Cross validation f1-score: 0.4922056062890573\n",
      "Dummy classifier f1-score:  0.26506024096385544\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "tengah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7751932503770739\n",
      "Cross validation f1-score: 0.5045365843792617\n",
      "Dummy classifier f1-score:  0.1624203821656051\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "tinggi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.47490004085748766\n",
      "Cross validation f1-score: 0.35305268003410417\n",
      "Dummy classifier f1-score:  0.10232558139534884\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menerima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7096703980099501\n",
      "Cross validation f1-score: 0.24511341991341995\n",
      "Dummy classifier f1-score:  0.11327433628318584\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "mengejar\n",
      "\n",
      "Training f1-score: 0.8706349206349207\n",
      "Cross validation f1-score: 0.7438235833486153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier f1-score:  0.38257575757575757\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.9071842136358265\n",
      "Cross validation f1-score: 0.7027362920304097\n",
      "Dummy classifier f1-score:  0.2309711286089239\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "jaringan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6727834357892161\n",
      "Cross validation f1-score: 0.4341324895733498\n",
      "Dummy classifier f1-score:  0.20202020202020202\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "halaman\n",
      "\n",
      "Training f1-score: 0.7462820356109684\n",
      "Cross validation f1-score: 0.4407159793611407\n",
      "Dummy classifier f1-score:  0.24637681159420288\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "harapan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7825140809011776\n",
      "Cross validation f1-score: 0.5161933641031771\n",
      "Dummy classifier f1-score:  0.2818428184281843\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kepala\n",
      "\n",
      "Training f1-score: 0.8089851584436422\n",
      "Cross validation f1-score: 0.4643509351486842\n",
      "Dummy classifier f1-score:  0.3046964490263459\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "mata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7869281943375925\n",
      "Cross validation f1-score: 0.4348387654657004\n",
      "Dummy classifier f1-score:  0.14371257485029942\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "buah\n",
      "\n",
      "Training f1-score: 0.9144764957264958\n",
      "Cross validation f1-score: 0.6348256912607473\n",
      "Dummy classifier f1-score:  0.2397003745318352\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "memecahkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7113420925263543\n",
      "Cross validation f1-score: 0.45805896443493344\n",
      "Dummy classifier f1-score:  0.2164821648216482\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "badan\n",
      "\n",
      "Training f1-score: 0.8047591939892365\n",
      "Cross validation f1-score: 0.4589361872695206\n",
      "Dummy classifier f1-score:  0.27255985267034993\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "jalan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6578725103579094\n",
      "Cross validation f1-score: 0.2012900372900373\n",
      "Dummy classifier f1-score:  0.1651376146788991\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "bintang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8284632034632035\n",
      "Cross validation f1-score: 0.46957622624289297\n",
      "Dummy classifier f1-score:  0.24113475177304963\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "kunci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.770840219510128\n",
      "Cross validation f1-score: 0.4812972866505475\n",
      "Dummy classifier f1-score:  0.14832535885167464\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "dasar\n",
      "\n",
      "Training f1-score: 0.6727040816326532\n",
      "Cross validation f1-score: 0.32359029859029864\n",
      "Dummy classifier f1-score:  0.176056338028169\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "membawa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.43927010417693646\n",
      "Cross validation f1-score: 0.2020529720905661\n",
      "Dummy classifier f1-score:  0.05442176870748299\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "jam\n",
      "\n",
      "Training f1-score: 0.7968608910469377\n",
      "Cross validation f1-score: 0.5868716804596137\n",
      "Dummy classifier f1-score:  0.17924528301886794\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "besar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.761980415667466\n",
      "Cross validation f1-score: 0.5201329182639511\n",
      "Dummy classifier f1-score:  0.15732758620689655\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "lebat\n",
      "\n",
      "Training f1-score: 0.7262178434592228\n",
      "Cross validation f1-score: 0.6735198135198136\n",
      "Dummy classifier f1-score:  0.3920265780730897\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "kaki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8186918445539134\n",
      "Cross validation f1-score: 0.6897949393601567\n",
      "Dummy classifier f1-score:  0.24444444444444446\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menjaga\n",
      "\n",
      "Training f1-score: 0.5413239588490018\n",
      "Cross validation f1-score: 0.22284643970127843\n",
      "Dummy classifier f1-score:  0.1634980988593156\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "asing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8678571428571429\n",
      "Cross validation f1-score: 0.8261893369788107\n",
      "Dummy classifier f1-score:  0.4825174825174825\n",
      "Best parameters:\n",
      "C : 1.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "layar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.8495703843029966\n",
      "Cross validation f1-score: 0.6261605993899227\n",
      "Dummy classifier f1-score:  0.3347826086956522\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "bidang\n",
      "\n",
      "Training f1-score: 0.4854014598540146\n",
      "Cross validation f1-score: 0.4855121293800539\n",
      "Dummy classifier f1-score:  0.4854014598540146\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "lingkungan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6325156325156325\n",
      "Cross validation f1-score: 0.49191944794526093\n",
      "Dummy classifier f1-score:  0.2222222222222222\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "baru\n",
      "\n",
      "Training f1-score: 0.9937859562611502\n",
      "Cross validation f1-score: 0.7831971424021112\n",
      "Dummy classifier f1-score:  0.284037558685446\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengandung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7661655929372465\n",
      "Cross validation f1-score: 0.5575730935730935\n",
      "Dummy classifier f1-score:  0.4895833333333333\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "atas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6482581611128786\n",
      "Cross validation f1-score: 0.45908923374761884\n",
      "Dummy classifier f1-score:  0.05970149253731344\n",
      "Best parameters:\n",
      "C : 0.5\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "sarung\n",
      "\n",
      "Training f1-score: 0.8549244213509685\n",
      "Cross validation f1-score: 0.8463680146207126\n",
      "Dummy classifier f1-score:  0.37\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengikat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.7056934524333289\n",
      "Cross validation f1-score: 0.3428054262409492\n",
      "Dummy classifier f1-score:  0.13793103448275862\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "bulan\n",
      "\n",
      "Training f1-score: 0.9612903225806451\n",
      "Cross validation f1-score: 0.9291436990428925\n",
      "Dummy classifier f1-score:  0.45614035087719296\n",
      "Best parameters:\n",
      "C : 0.25\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "coklat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.48084284418689566\n",
      "Cross validation f1-score: 0.38965709614381183\n",
      "Dummy classifier f1-score:  0.3037974683544304\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "cerah\n",
      "\n",
      "Training f1-score: 0.6912280701754386\n",
      "Cross validation f1-score: 0.6339094481861101\n",
      "Dummy classifier f1-score:  0.47586206896551725\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "nilai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6896004890250413\n",
      "Cross validation f1-score: 0.29982570491084426\n",
      "Dummy classifier f1-score:  0.12085308056872036\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "dunia\n",
      "\n",
      "Training f1-score: 0.776680190150139\n",
      "Cross validation f1-score: 0.4732409424506199\n",
      "Dummy classifier f1-score:  0.1794871794871795\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "menangkap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.749404761904762\n",
      "Cross validation f1-score: 0.4406626596262592\n",
      "Dummy classifier f1-score:  0.29508196721311475\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mendorong\n",
      "\n",
      "Training f1-score: 0.7174975562072337\n",
      "Cross validation f1-score: 0.5010236533251292\n",
      "Dummy classifier f1-score:  0.4672364672364672\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "menyusun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.6694055944055943\n",
      "Cross validation f1-score: 0.3839923884340103\n",
      "Dummy classifier f1-score:  0.24242424242424243\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 20\n",
      "----------------------------------\n",
      "==================================\n",
      "mengeluarkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training f1-score: 0.5717967186874751\n",
      "Cross validation f1-score: 0.35231663399637947\n",
      "Dummy classifier f1-score:  0.13970588235294118\n",
      "Best parameters:\n",
      "C : 2.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "==================================\n",
      "mengisi\n",
      "\n",
      "Training f1-score: 0.6328518920624184\n",
      "Cross validation f1-score: 0.2794133334845409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier f1-score:  0.14791666666666667\n",
      "Best parameters:\n",
      "C : 4.0\n",
      "max_iter : 40\n",
      "----------------------------------\n",
      "==================================\n",
      "panas\n",
      "\n",
      "Training f1-score: 0.7927829224816311\n",
      "Cross validation f1-score: 0.6065490688722488\n",
      "Dummy classifier f1-score:  0.23008849557522124\n",
      "Best parameters:\n",
      "C : 8.0\n",
      "max_iter : 10\n",
      "----------------------------------\n",
      "Cross validation macro average f1-score: 0.4847205469988656\n",
      "Dummy classifier macro average f1-score: 0.25266422986045856\n",
      "elapsed time: 12.434107830999892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/nakama/Documents/StateOfTheArtWSD/nlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "begin = time.perf_counter()\n",
    "train_all_f1(\n",
    "    LinearSVC(),\n",
    "    {'max_iter': [10, 20, 40], 'C':[0.25, 0.5, 1.0, 2.0, 4.0, 8.0]},\n",
    "    algorithm_name='Linear SVM'\n",
    ")\n",
    "print('elapsed time:', time.perf_counter() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.84,\n",
       "  'recall': 0.9130434782608695,\n",
       "  'f1-score': 0.8749999999999999,\n",
       "  'support': 46},\n",
       " '1': {'precision': 0.9433962264150944,\n",
       "  'recall': 0.8064516129032258,\n",
       "  'f1-score': 0.8695652173913043,\n",
       "  'support': 62},\n",
       " '2': {'precision': 0.8181818181818182,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9,\n",
       "  'support': 27},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.9166666666666666,\n",
       "  'f1-score': 0.9565217391304348,\n",
       "  'support': 12},\n",
       " 'accuracy': 0.8843537414965986,\n",
       " 'macro avg': {'precision': 0.9003945111492282,\n",
       "  'recall': 0.9090404394576904,\n",
       "  'f1-score': 0.9002717391304347,\n",
       "  'support': 147},\n",
       " 'weighted avg': {'precision': 0.892663096113231,\n",
       "  'recall': 0.8843537414965986,\n",
       "  'f1-score': 0.8839544513457556,\n",
       "  'support': 147}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(\n",
    "    y_train[list(dataset.query('kata == \"{}\"'.format('kunci')).index)], \n",
    "    classifier['kunci'].predict(X_train[list(dataset.query('kata == \"{}\"'.format('kunci')).index)]),\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
